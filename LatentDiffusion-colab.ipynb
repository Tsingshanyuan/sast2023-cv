{"cells":[{"cell_type":"markdown","id":"ed0197ef","metadata":{"id":"ed0197ef"},"source":["<a href=\"https://colab.research.google.com/github/Kevin-thu/sast2023-cv/blob/master/LatentDiffusion-colab.ipynb#scrollTo=ec7d6dc4\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":22,"id":"55e50b25","metadata":{"id":"55e50b25","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691029801079,"user_tz":-480,"elapsed":460,"user":{"displayName":"张子文","userId":"00046281389081327823"}},"outputId":"80cd9e66-e4f0-478d-b84c-9193d6693d8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline"]},{"cell_type":"code","execution_count":23,"id":"6073b910","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6073b910","executionInfo":{"status":"ok","timestamp":1691029812727,"user_tz":-480,"elapsed":11070,"user":{"displayName":"张子文","userId":"00046281389081327823"}},"outputId":"aee2aff6-7e39-4027-d0f7-d555fb979778"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lightning==2.0.5 in /usr/local/lib/python3.10/dist-packages (2.0.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.19.3)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n","Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (3.1.2)\n","Requirement already satisfied: PyYAML<8.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (6.0.1)\n","Requirement already satisfied: arrow<3.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (1.2.3)\n","Requirement already satisfied: backoff<4.0,>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (2.2.1)\n","Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (4.11.2)\n","Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (8.1.6)\n","Requirement already satisfied: croniter<1.5.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (1.4.1)\n","Requirement already satisfied: dateutils<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (0.6.12)\n","Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (6.3.1)\n","Requirement already satisfied: fastapi<2.0,>=0.92.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (0.100.1)\n","Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (2023.6.0)\n","Requirement already satisfied: inquirer<5.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (3.1.3)\n","Requirement already satisfied: lightning-cloud>=0.5.37 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (0.5.37)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (0.9.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (23.1)\n","Requirement already satisfied: psutil<7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (5.9.5)\n","Requirement already satisfied: pydantic<2.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (1.10.12)\n","Requirement already satisfied: python-multipart<2.0,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (0.0.6)\n","Requirement already satisfied: requests<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (2.27.1)\n","Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (13.4.2)\n","Requirement already satisfied: starlette in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (0.27.0)\n","Requirement already satisfied: starsessions<2.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (1.3.0)\n","Requirement already satisfied: torch<4.0,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (2.0.1+cu118)\n","Requirement already satisfied: torchmetrics<2.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (1.0.1)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (4.65.0)\n","Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (5.7.1)\n","Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (4.7.1)\n","Requirement already satisfied: urllib3<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (1.26.16)\n","Requirement already satisfied: uvicorn<2.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (0.23.2)\n","Requirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (1.6.1)\n","Requirement already satisfied: websockets<13.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (11.0.3)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning==2.0.5) (2.0.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers) (4.6.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning==2.0.5) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning==2.0.5) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.11.0->lightning==2.0.5) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning==2.0.5) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<4.0,>=1.11.0->lightning==2.0.5) (16.0.6)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.7.18)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning==2.0.5) (2.4.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateutils<2.0->lightning==2.0.5) (2022.7.1)\n","Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff<8.0,>=5.7.0->lightning==2.0.5) (4.1.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (3.8.5)\n","Requirement already satisfied: blessed>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning==2.0.5) (1.20.0)\n","Requirement already satisfied: python-editor>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning==2.0.5) (1.0.4)\n","Requirement already satisfied: readchar>=3.0.6 in /usr/local/lib/python3.10/dist-packages (from inquirer<5.0,>=2.10.0->lightning==2.0.5) (4.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<5.0->lightning==2.0.5) (2.1.3)\n","Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.37->lightning==2.0.5) (2.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from lightning-cloud>=0.5.37->lightning==2.0.5) (1.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning==2.0.5) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning==2.0.5) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<4.0->lightning==2.0.5) (3.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning==2.0.5) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning==2.0.5) (2.14.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning==2.0.5) (3.7.1)\n","Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning==2.0.5) (2.1.2)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<2.0->lightning==2.0.5) (0.14.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning==2.0.5) (1.3.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning==2.0.5) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning==2.0.5) (1.1.2)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning==2.0.5) (0.2.6)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning==2.0.5) (0.1.2)\n","Requirement already satisfied: setuptools>=41.0 in /usr/local/lib/python3.10/dist-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning==2.0.5) (67.7.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.11.0->lightning==2.0.5) (1.3.0)\n"]}],"source":["#!git clone https://github.com/Kevin-thu/sast2023-cv\n","!pip install lightning==2.0.5 transformers diffusers einops torchvision numpy matplotlib imageio scikit-image kornia"]},{"cell_type":"markdown","id":"ce528bb2","metadata":{"id":"ce528bb2"},"source":["# Latent Diffusion Training\n","\n","In this notebook, we will train a simple `LatentDiffusion` model.\n","\n","The training should take up to 20 hours for reasonable results.\n","\n","Ideally, you will download this dataset once and store it as `./afhq`. If you're running on colab, it's a good idea to download it once to your personal machine (it's only 240 MB) and then upload it to your colab space when you start a new notebook."]},{"cell_type":"code","execution_count":29,"id":"ec7d6dc4","metadata":{"id":"ec7d6dc4","executionInfo":{"status":"ok","timestamp":1691030005384,"user_tz":-480,"elapsed":8972,"user":{"displayName":"张子文","userId":"00046281389081327823"}}},"outputs":[],"source":["import sys\n","sys.path.append('/content/drive/MyDrive/ColabNotebooks/projects/sast2023-cv') #替换成实际路径\n","sys.argv = ['ipykernel_launcher.py']\n","\n","import os, sys, argparse\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pytorch_lightning as pl\n","from pytorch_lightning import seed_everything\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import imageio\n","\n","from src import *\n","\n","mpl.rcParams['figure.figsize'] = (8, 8)"]},{"cell_type":"code","execution_count":30,"id":"e3ac8810","metadata":{"id":"e3ac8810","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691030019002,"user_tz":-480,"elapsed":373,"user":{"displayName":"张子文","userId":"00046281389081327823"}},"outputId":"9f2a751b-4718-411e-ec0d-e17e109d9824"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"]},{"output_type":"execute_result","data":{"text/plain":["42"]},"metadata":{},"execution_count":30}],"source":["# Note: Actually it's totally unnecessay and silly to use argparse in jupyter notebook.\n","# But anyway, it's a good chance to do some practice and it will definitey be useful someday.\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--image_size\", type=int, default=256, help=\"Image size\")\n","parser.add_argument(\"--train_dataset\", type=str, default=\"./afhq/\", help=\"The path to your training dataset\")\n","parser.add_argument(\"--device\", type=str, default=0 if torch.cuda.is_available() else \"cpu\", help=\"Device number.\")\n","parser.add_argument(\"--num_workers\", type=int, default=0, help=\"Spawn how many processes to load data.\")\n","parser.add_argument(\"--seed\", type=int, default=42, help='manual seed')\n","parser.add_argument(\"--max_epochs\", type=int, default=1000, help=\"Max epoch number to run.\")\n","parser.add_argument(\"--ckpt_path\", type=str, default=\"\", help=\"Checkpoint path to load.\")\n","parser.add_argument(\"--save_path\", type=str, default=\"./ckpt/\", help=\"Checkpoint path to save.\")\n","parser.add_argument(\"--save_freq\", type=int, default=1, help=\"Save model every how many epochs.\")\n","parser.add_argument(\"--ddim_steps\", type=int, default=50, help=\"DDIM timesteps\")\n","# TODO begin: Add arguments lr and batch_size. It's recommended to set default lr to 1e-4 and default batch_size to 8.\n","parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"Learning rate\")\n","parser.add_argument(\"--batch_size\", type=int, default=8, help=\"Batch size\")\n","# TODO end\n","args = parser.parse_args()\n","seed_everything(args.seed)"]},{"cell_type":"markdown","id":"422ec7fb","metadata":{"id":"422ec7fb"},"source":["### Prepare dataset and dataloader"]},{"cell_type":"code","execution_count":31,"id":"effe3e3a","metadata":{"id":"effe3e3a","executionInfo":{"status":"ok","timestamp":1691031628458,"user_tz":-480,"elapsed":375,"user":{"displayName":"张子文","userId":"00046281389081327823"}}},"outputs":[],"source":["from kornia.utils import image_to_tensor\n","import kornia.augmentation as KA\n","\n","class SimpleImageDataset(Dataset):\n","    \"\"\"Dataset returning images in a folder.\"\"\"\n","\n","    def __init__(self,\n","                 root_dir,\n","                 transforms = None):\n","\n","        self.root_dir = root_dir\n","        self.transforms = transforms\n","\n","        # set up transforms\n","        if self.transforms is not None:\n","            data_keys = ['input']\n","\n","            self.input_T = KA.container.AugmentationSequential(\n","                *self.transforms,\n","                data_keys = data_keys,\n","                same_on_batch = False\n","            )\n","\n","        # TODO begin: Define the image paths filtered by the `supported_formats` in your datasets\n","        # Hint: os.listdir\n","        # Challenge: Can you complete this task in one line? (hint: Python comprehension, refer to Python basics handout by Yifan Li)\n","        supported_formats = [\"jpg\", \"png\"]\n","        self.image_names = [f for f in os.listdir(root_dir) if f.split('.')[-1] in supported_formats]\n","        # TODO end\n","\n","    def __len__(self):\n","        # TODO begin: Return the length of your dataset\n","        return len(self.image_names)\n","        # TODO end\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.root_dir, self.image_names[idx])\n","        image = image_to_tensor(imageio.imread(img_name)) / 255\n","\n","        if self.transforms is not None:\n","            image = self.input_T(image)[0]\n","\n","        return image"]},{"cell_type":"code","execution_count":null,"id":"528e3f70","metadata":{"id":"528e3f70"},"outputs":[],"source":["import torchvision.transforms as T\n","\n","CROP_SIZE = args.image_size\n","\n","transform = [\n","    KA.RandomCrop((2 * CROP_SIZE,2 * CROP_SIZE)),\n","    KA.Resize((CROP_SIZE, CROP_SIZE), antialias=True),\n","    KA.RandomVerticalFlip()\n","  ]\n","\n","train_dataset = SimpleImageDataset(args.train_dataset, transforms = transform)"]},{"cell_type":"code","execution_count":null,"id":"4534f313","metadata":{"id":"4534f313"},"outputs":[],"source":["# TODO begin: Define the training dataloader using torch.utils.data.DataLoader\n","# Hint: check the API of torch.utils.data.DataLoader, especially arguments like batch_size, shuffle, num_workers\n","train_dataloader = None\n","# TODO end"]},{"cell_type":"markdown","id":"82e372cc","metadata":{"id":"82e372cc"},"source":["### Model Training"]},{"cell_type":"code","execution_count":null,"id":"04156f52","metadata":{"id":"04156f52"},"outputs":[],"source":["from src import *\n","\n","# TODO begin: complete the LatentDiffusion Model in `src`\n","model = LatentDiffusion(lr = args.lr, batch_size = args.batch_size)\n","# TODO end"]},{"cell_type":"markdown","id":"a92f33e5","metadata":{"id":"a92f33e5"},"source":["...but first, let's check if the used `AutoEncoder` (`model.vae`) can reconstruct our samples well.\n","\n","**You should always test your autoencoder in this way when using latent diffusion models on a new dataset.**"]},{"cell_type":"code","execution_count":null,"id":"786b43c8","metadata":{"id":"786b43c8"},"outputs":[],"source":["img = train_dataset[0]\n","\n","# TODO begin: Show the example img and use vae to reconstruct it using matplotlib\n","# Hint: plt.imshow\n","# Challenge: What's the image shape here? Should you permute or unsqueeze it?\n","plt.subplot(1,2,1)\n","# Plot the original img here\n","\n","plt.title('Input')\n","\n","plt.subplot(1,2,2)\n","# Plot the reconstructed img by `mode.vae` here\n","\n","plt.title('AutoEncoder Reconstruction')\n","# TODO end"]},{"cell_type":"code","execution_count":null,"id":"1a83cab8","metadata":{"id":"1a83cab8"},"outputs":[],"source":["# Define the trainer using PyTorch Lightning\n","from lightning.pytorch.callbacks import ModelCheckpoint\n","\n","checkpoint_callback = ModelCheckpoint(dirpath=args.save_path, every_n_epochs=args.save_freq)\n","\n","# TODO: You can specify other parameters here, like accelerator, devices...\n","# You can check the pl.Trainer API here: https://lightning.ai/docs/pytorch/stable/common/trainer.html\n","trainer = pl.Trainer(\n","    max_epochs = args.max_epochs,\n","    callbacks = [EMA(0.9999), checkpoint_callback]\n",")"]},{"cell_type":"code","execution_count":null,"id":"deafb040","metadata":{"id":"deafb040"},"outputs":[],"source":["# Easy to train the model in PyTorch Lightning in one line\n","trainer.fit(model, train_dataloaders=train_dataloader, ckpt_path=args.ckpt_path if args.ckpt_path else None)\n","# TODO Challenge: Can you add some logging and visualization codes to better babysitting the training process?\n","# Hint: There are many librarys you can use, e.g. logging, tensorboard, wandb... And the easiest way: print the loss every step."]},{"cell_type":"markdown","id":"789d9c71","metadata":{"id":"789d9c71"},"source":["Go to sleep now ~ This one line might run for days...\n","\n","Wait! Please make sure that you have save the checkpoints correctly.\n","\n","If the code breaks for some reason, you can load the checkpoint and continue training.\n","\n","### Now sample images from your model!"]},{"cell_type":"code","execution_count":null,"id":"c4faf7bd","metadata":{"id":"c4faf7bd"},"outputs":[],"source":["model.to(args.device)\n","out = model(batch_size = args.batch_size, shape = (64,64), verbose = True)\n","# You can also try `sampler=DDIM_Sampler(num_steps=args.ddim_steps)`, which can sample images in less than 50 steps.\n"]},{"cell_type":"code","execution_count":null,"id":"aeddad22","metadata":{"id":"aeddad22"},"outputs":[],"source":["for idx in range(out.shape[0]):\n","    plt.subplot(1,len(out),idx+1)\n","    plt.imshow(out[idx].detach().cpu().permute(1,2,0))\n","    plt.axis('off')"]}],"metadata":{"kernelspec":{"display_name":"ldm","language":"python","name":"python3"},"language_info":{"name":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}